{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ccffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai dotenv tiktoken pandas tqdm qdrant_client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37061a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "\n",
    "CHANNEL_NAME = \"bluepigeon0810\"  # example channel name\n",
    "JSON_PATH = f\"{CHANNEL_NAME}.jsonl\"\n",
    "COLLECTION_NAME = f\"{CHANNEL_NAME}_videos\"\n",
    "\n",
    "# ==== Configuration ====\n",
    "#TODO: replace with your actual keys\n",
    "QDRANT_URL = \"your_qdrant_url\"       # e.g. \"https://xxxx-xxxxx.eu-central.aws.cloud.qdrant.io\"\n",
    "QDRANT_API_KEY = \"your_qdrant_api_key\"     # from your Qdrant Cloud dashboard\n",
    "OPENAI_API_KEY = \"your_openai_api_key\"\n",
    "\n",
    "EMBED_MODEL = \"text-embedding-3-small\"\n",
    "MAX_TOKENS = 8150\n",
    "encoding = tiktoken.encoding_for_model(EMBED_MODEL)\n",
    "vector_size = 1536 if EMBED_MODEL == \"text-embedding-3-small\" else 3072\n",
    "# ==== Helper function ====\n",
    "def clean_srt(transcript: str) -> str:\n",
    "    \"\"\"Strip SRT formatting (timestamps, line numbers).\"\"\"\n",
    "    lines = transcript.splitlines()\n",
    "    cleaned = [line.strip() for line in lines if line.strip() and not line.strip().isdigit() and \"-->\" not in line]\n",
    "    return \" \".join(cleaned)\n",
    "\n",
    "# ==== Initialize clients ====\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# --- Qdrant Cloud connection ---\n",
    "qdrant = QdrantClient(\n",
    "    url=QDRANT_URL,\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "\n",
    "# ==== Load JSON ====\n",
    "df = pd.read_json(JSON_PATH, lines=True)\n",
    "\n",
    "# ==== Create or reset collection ====\n",
    "existing = [c.name for c in qdrant.get_collections().collections]\n",
    "if COLLECTION_NAME not in existing:\n",
    "    qdrant.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    "    )\n",
    "    print(f\"✅ Created collection '{COLLECTION_NAME}'\")\n",
    "else:\n",
    "    print(f\"ℹ️ Collection '{COLLECTION_NAME}' already exists. Clearing existing data...\")\n",
    "    qdrant.delete_collection(collection_name=COLLECTION_NAME)\n",
    "    qdrant.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    "    )\n",
    "    print(f\"✅ Re-created collection '{COLLECTION_NAME}'\")\n",
    "\n",
    "# ==== Embed & upload ====\n",
    "points = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Embedding & uploading\"):\n",
    "    text = row[\"transcript\"]\n",
    "    video_id = row[\"video_id\"]\n",
    "    upload_date = row[\"upload_date\"]\n",
    "    video_title = row[\"title\"]\n",
    "\n",
    "    embedding_input = clean_srt(text)\n",
    "\n",
    "    tokens = encoding.encode(embedding_input)\n",
    "    if len(tokens) > MAX_TOKENS:\n",
    "        tokens = tokens[:MAX_TOKENS]\n",
    "        embedding_input = encoding.decode(tokens)\n",
    "\n",
    "    emb = client.embeddings.create(\n",
    "        model=EMBED_MODEL,\n",
    "        input=embedding_input\n",
    "    ).data[0].embedding\n",
    "\n",
    "    points.append(PointStruct(\n",
    "        id=idx,\n",
    "        vector=emb,\n",
    "        payload={\n",
    "            \"video_id\": video_id,\n",
    "            \"title\": video_title,\n",
    "            \"upload_date\": upload_date,\n",
    "            \"transcript\": text\n",
    "        }\n",
    "    ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1a864f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload in batches to avoid timeout\n",
    "BATCH_SIZE = 50\n",
    "for i in range(0, len(points), BATCH_SIZE):\n",
    "    batch = points[i:i + BATCH_SIZE]\n",
    "    qdrant.upsert(collection_name=COLLECTION_NAME, points=batch)\n",
    "    print(f\"✅ Uploaded batch {i // BATCH_SIZE + 1}/{len(points) // BATCH_SIZE + 1}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
